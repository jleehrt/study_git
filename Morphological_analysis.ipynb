{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Morphological_analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP6mE3kyIrfxt7mNiGxW8VV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wedms6-IXSjY"
      },
      "source": [
        "## 형태소 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQhIM57SX9Cq"
      },
      "source": [
        "# 불용어 사전 로드\r\n",
        "# stopwords = open(DIC_STOPWORDS_FILE, 'r').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0QsbftbYijT"
      },
      "source": [
        "# print(komoran.morphs('김유플은 5G 중계기 운영을 합니다.'))\r\n",
        "# print(komoran.pos('김유플은 5G 중계기 운영을 합니다.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJJY1MzmYu3u"
      },
      "source": [
        "# text_data\r\n",
        "\r\n",
        "# 형태소 분석기\r\n",
        "# from konlpy.tag import Komoran\r\n",
        "# komoran = Komoran(userdic = DIC_ALL_FILE) # 사용자 사전 추가\r\n",
        "\r\n",
        "# temp = []\r\n",
        "# result = []\r\n",
        "# pos_list = ['NNG', 'NNB', 'VA', 'VX', 'VV', 'VA', 'MM', 'MAG', 'MAG', 'MAJ', 'XPN', 'XR', 'SN', 'ZN', 'ZV', 'ZZ', 'SL']\r\n",
        "\r\n",
        "for sentence in text_data:\r\n",
        "    if len(sentence.strip()) > 0: # strip 추가하여 빈칸 없애기\r\n",
        "    pos_tag = [i[0] for i in komoran.pos(sentence) if i[1] in pos_list]\r\n",
        "    # 숫자만으로 되어 있는 것 제거\r\n",
        "    pos_tag = [i for i in pos_tag if not isNumber(i)]\r\n",
        "    # 단어 내 빈칸 제거\r\n",
        "    pos_tag = [i.replace(' ', '') for i in pos_tag]\r\n",
        "    # 불용어 제거\r\n",
        "    pos_tag = [i for i in pos_tag if i not in stopwords]\r\n",
        "    temp.append(pos_tag)\r\n",
        "    else:\r\n",
        "        temp.append('')\r\n",
        "result = [i for i in temp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NGlF14EaGu3"
      },
      "source": [
        "## 문장에서 do 뽑아내기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndonfny5cA6c"
      },
      "source": [
        "# do 사전 읽기\r\n",
        "# f = open(DIC_DO_FILE, 'r')\r\n",
        "# lines = f.read()\r\n",
        "# f.close()\r\n",
        "# dic_do = lines.split('\\n')\r\n",
        "# print(dic_do)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUz-YUX0ce3y"
      },
      "source": [
        "# result_do = []\r\n",
        "# for i in text_data:\r\n",
        "#     result_do.append(re.findall(r\"(?=(\"+'|'.join(dic_do)+r\"))\", i))\r\n",
        "# print(len(result_do))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA7mkJkDdEKH"
      },
      "source": [
        "# 결과 확인\r\n",
        "# df['do_결과_원데이터'] = [list(set(i)) for i in result_do]\r\n",
        "# df['do_결과_추출된 단어개수'] = [len(list(set(i))) for i in result_do]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3WAjmq_ep61"
      },
      "source": [
        "## 테스트 형태소 분석기 사용 후 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IPK8BTKevvC"
      },
      "source": [
        "# 구분자 ' '로 각 행의 배열 합치기\r\n",
        "# result_line = [' '.join(i) for i in result]\r\n",
        "# result_do_afterTextmining = []\r\n",
        "# for i in result_line:\r\n",
        "#     print(re.findall(r\"(?=(\"+'|'.join(dic_do)+r\"))\", i))\r\n",
        "#     result_do_afterTextmining.append(re.findall(r\"(?=(\"+'|'.join(dic_do)+r\"))\", i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmGx1O8Zd5jj"
      },
      "source": [
        "## 문장에서 object 뽑아내기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF758v_wdrpd"
      },
      "source": [
        "# object 사전 읽기\r\n",
        "# f = open(DIC_OBJECT_FILE, 'r')\r\n",
        "# lines = f.read()\r\n",
        "# f.close()\r\n",
        "# dic_object = lines.split('\\n')\r\n",
        "# print(dic_object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcfs5M1PeH7D"
      },
      "source": [
        "# result_object = []\r\n",
        "# for i in text_data:\r\n",
        "#     result_do.append(re.findall(r\"(?=(\"+'|'.join(dic_do)+r\"))\", i))\r\n",
        "# print(len(result_object))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeJyYIvieH7R"
      },
      "source": [
        "# 결과 확인\r\n",
        "# df['object_결과_원데이터'] = [list(set(i)) for i in result_object]\r\n",
        "# df['object_결과_추출된 단어개수'] = [len(list(set(i))) for i in result_object]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsNBQELZfo68"
      },
      "source": [
        "# do_list = []\r\n",
        "# tmp_list = []\r\n",
        "\r\n",
        "# for i in result_do_afterTextmining:\r\n",
        "#     tmp_list.extend(i)\r\n",
        "\r\n",
        "# do_list = list(set(tmp_list))\r\n",
        "# print(do_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}