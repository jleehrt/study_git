{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyuCp8TXluqhLiOQWgaNXU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrQ3cCu9HbyO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y0sRPp1HqZO"
      },
      "source": [
        "dtype = torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkut4P9aHxR8"
      },
      "source": [
        "sentence = [\"가 을 은 독 서 의 계 절 \\t B I I B I I B I\", \"새 로 운 해 가 밝 았 다 \\t B I I B I B I I\",\n",
        "            \"내 가 쿠 키 를 구 웠 어 요 \\t B I B I I B I I I\", \"당 신 은 나 를 본 적 이 있 나 요 ? \\t B I I B I B B I B I I I\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYGHTmr_IamK"
      },
      "source": [
        "datas = []\n",
        "eumjeol_sequence = [] # 음절 집합\n",
        "correct_labels = [] # 정답 집합\n",
        "\n",
        "for sen in sentence:\n",
        "    pieces = sen.strip().split(\"\\t\")\n",
        "    sequence, label = pieces[0].strip().split(), pieces[1].strip().split()\n",
        "\n",
        "    eumjeol_sequence.append(sequence)\n",
        "    correct_labels.append(label)\n",
        "\n",
        "    datas.append((sequence, label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVsZMDZVJM21"
      },
      "source": [
        "word = []\n",
        "max_len = 0\n",
        "for sequence, label in datas:\n",
        "    if len(sequence) > max_len:\n",
        "        max_len = len(sequence)\n",
        "    for sen in sequence:\n",
        "        if sen not in word:\n",
        "            word.append(sen)\n",
        "\n",
        "    word_dict = {w:i for i, w in enumerate(word)}\n",
        "    number_dict = {i:w for i, w in enumerate(word)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dqsD9RUKmwz"
      },
      "source": [
        "tag2idx = {\"PAD_ID\":0, \"B\":1, \"I\":2}\n",
        "idx2tag = {0:\"PAD_ID\", 1:\"B\", 2:\"I\"}\n",
        "\n",
        "n_size = len(sentence) # 문장 개수\n",
        "n_class = len(tag2idx) # 띄어쓰기 여부\n",
        "vocab_size = len(word_dict)\n",
        "n_hidden = 64\n",
        "n_embedding = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3NRUC1K0q46"
      },
      "source": [
        "def make_batch(datas):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "\n",
        "    for sentence, label in datas:\n",
        "        input = []\n",
        "        target = []\n",
        "        for n, sen in enumerate(sentence):\n",
        "            input.append(word_dict[sen])\n",
        "            target.append(tag2idx[label[n]])\n",
        "\n",
        "        input = input + [0] * (max_len - len(input))\n",
        "        target = target + [tag2idx[\"PAD_ID\"]] * (max_len - len(target))\n",
        "        input_batch.append(input)\n",
        "        target_batch.append(target)\n",
        "    return Variable(torch.LongTensor(input_batch)), Variable(torch.LongTensor(target_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQUGDWTg2Anr"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, n_embedding)\n",
        "        self.lstm = nn.LSTM(input_size = n_embedding, hidden_size = n_hidden, bidirectional = True, batch_first = True) \n",
        "        self.fc = nn.Linear(n_hidden * 2, n_class)\n",
        "\n",
        "    def forward(self, X): \n",
        "        input = self.embed(X)\n",
        "        \n",
        "        hidden_state = Variable(torch.zeros(1*2, len(X), n_hidden)) # [num_layers(=1)* num_directions(=2), batch_size, n_hidden)\n",
        "        cell_state = Variable(torch.zeros(1*2, len(X), n_hidden))\t# [num_layeis(=1)* num_directions(=2), batch_size, n_hidden)\n",
        "\n",
        "        outputs, (_, _) = self.lstm(input, (hidden_state, cell_state))\n",
        "        predictions = self.fc(outputs) \n",
        "        return predictions.permute(0, 2, 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDlGFVzYA8dA"
      },
      "source": [
        "input_batch, target_batch = make_batch(datas) \n",
        "model = BiLSTM()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag2idx[\"PAD_ID\"]) \n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kpy_KKKOQen"
      },
      "source": [
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_batch)\n",
        "    loss = criterion(output, target_batch) \n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print('Epoch:', '%04d'% (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "        \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "predict = model(input_batch).data.max(1, keepdim = True)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM0yeRtKMEND"
      },
      "source": [
        "model(input_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEV4wOl9A9Ib"
      },
      "source": [
        "predict_labels = predict.numpy() \n",
        "print(predict_labels) \n",
        "for i in range(len(eumjeol_sequence)): \n",
        "    correct_sentence = ''\n",
        "    predict_sentence = ''\n",
        "    for j in range(en(eumjeol_sequence[i])): \n",
        "        if (j!= 0) & (correct_labels[i][j] == 'B'): \n",
        "            correct_sentence += \" \" \n",
        "        correct_sentence += eumjeol_sequence[i][j]\n",
        "\n",
        "        if (j != 0) & (predict_label[i][0][j] == 1): \n",
        "            predict_sentence += \" \" \n",
        "            predict_sentence += eumjeol_sequence[i][j] \n",
        "        \n",
        "    print('정답 문장:' + correct_sentence) \n",
        "    print('출력 문장:' predict_sentence) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc-LsfU_A9NX"
      },
      "source": [
        "self.embed = nn.Embedding(vocab_size, n_embedding) It> selfIstm = nn.LSTM(input_size=n_embedding, hidden_size=n_hidden, bidirectional=True, batch_first=True) self.fc = nn.Linear(n_hidden * 2, n_class) \n",
        "def forward(self, X): input = self.embed(X) \n",
        "hidden_state = Variable(torch.zeros(1*2, len(X), n_hidden))\n",
        "cell_state = vanabie(torcn.zeros(iwz, len(X), n_nicicien))\n",
        "outputs, (_, J = selfistm(input, (hidden_state, cell_state)) \n",
        "predictions = self.fc(outputs) return predictions.permute(0, 2, 1) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
