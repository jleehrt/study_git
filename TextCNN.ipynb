{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextCNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPi5/DCk7g6cWd5eeoGZAIi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWUmWebduOHE"
      },
      "source": [
        "sentences = ['i love you', 'he loves me', 'she likes baseball', 'i hate you', 'sorry for that', 'this is awful']\n",
        "labels = [1, 1, 1, 0, 0, 0] # 1 is good, 0 is not good"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32eRDH_juOnc"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "\n",
        "# Text-CNN Parameter\n",
        "embedding_size = 2\n",
        "sequence_length = 3\n",
        "num_classes = 2\n",
        "filter_sizes = [2, 2, 2]\n",
        "num_filters = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u1ePsevv7Jz"
      },
      "source": [
        "word_list = ' '.join(sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "vocab_size = len(word_dict)\n",
        "\n",
        "inputs = []\n",
        "for sen in sentences:\n",
        "    inputs.append(np.array([word_dict[n] for n in sen.split()]))\n",
        "\n",
        "targets = []\n",
        "for out in labels:\n",
        "    targets.append(out)\n",
        "\n",
        "input_batch = Variable(torch.LongTensor(inputs))\n",
        "target_batch = Variable(torch.LongTensor(targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ1moCRIyAyu"
      },
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.num_filters_total = num_filters * len(filter_sizes)\n",
        "        self.W = nn.Parameter(torch.empty(vocab_size, embedding_size).uniform_(-1, 1)).type(dtype)\n",
        "        self.Weight = nn.Parameter(torch.empty(self.num_filters_total, num_classes).uniform_(-1, 1)).type(dtype)\n",
        "        self.Bias = nn.Parameter(0.1 * torch.ones([num_classes])).type(dtype)\n",
        "\n",
        "    def forward(self, X):\n",
        "        embedded_chars = self.W[X]\n",
        "        embedded_chars = embedded_chars.unsqueeze(1)\n",
        "\n",
        "        pooled_outputs = []\n",
        "        for filter_size in filter_sizes:\n",
        "\n",
        "            conv = nn.Conv2d(1, num_filters, (filter_size, embedding_size), bias = True)(embedded_chars)      \n",
        "            h = F.relu(conv)\n",
        "            np = nn.MaxPool2d((sequence_length - filter_size + 1, 1))\n",
        "\n",
        "            pooled = np(h).permute(0, 3, 2, 1)\n",
        "\n",
        "        h_pool = torch.cat(pooled_outputs, -1)\n",
        "        h_pool_flat = torch.reshape(h_pool, [-1, self.num_filters_total])\n",
        "\n",
        "        model = torch.nn(h_pool_flat, self.Weight) + self.Bias\n",
        "        return model\n",
        "\n",
        "model = TextCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92yWOo4Gvly"
      },
      "source": [
        "특정한 값으로 초기화를 하지 않는 행렬 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIps9jAf4TMV"
      },
      "source": [
        "torch.empty(3, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfb3E7JzGuFB"
      },
      "source": [
        "## nn.MaxPool2d()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8qBQPwlG7uo"
      },
      "source": [
        "import torch.__config__\n",
        "m1 = nn.MaxPool2d(3, stride = 2)\n",
        "print('m1:\\n', m1, '\\n')\n",
        "\n",
        "m2 = nn.MaxPool2d((3, 2), stride = (2, 1))\n",
        "input = torch.randn(20, 16, 50, 32)\n",
        "output = m2(input)\n",
        "print('m2:\\n', m2, '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2CDyf7fHipE"
      },
      "source": [
        "for epoch in range(5000):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_batch)\n",
        "\n",
        "    loss = criterion(output, target_batch)\n",
        "    if(epoch + 1) % 1000 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:6f'.format(loss))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "test_text = 'sorry hate you'\n",
        "tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
        "test_batch = Variable(torch.LongTensor(tests))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Pred\n",
        "predict = model(test_batch).data.max(1, keepdin = True)[1]\n",
        "if predict[0][0] == 0:\n",
        "    print(test_text, 'is Bad Mean...')\n",
        "else:\n",
        "    print(test_text, 'is Good Mean!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnC2Ad7oJAvR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}