{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNGxylXrWzZOLjrj5S2N+AR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTHC0VtLg8uX"
      },
      "source": [
        "## w2v을 위한 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfUJMNVuhDI3"
      },
      "source": [
        "# 형태소 분석만 한 결과\r\n",
        "# result_onlyMorphologicalAnalysis_w2vdata = df_sample2['형태소분석 결과']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YID_OT9ghFbI"
      },
      "source": [
        "# word embedding iter 500, size 100\r\n",
        "# from gensim.models import Word2Vec\r\n",
        "# embedding_model3 = Word2Vec(result_onlyMorphologicalAnalysis_w2vdata, size = 100, window =2, mon_count = 1, workers = 4, iter = 500, sg = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B5Nipkeh1b8"
      },
      "source": [
        "컨텐츠를 100차원의 벡터로 바꾸고, 주변단어(window)는 앞뒤로 두개까지, 코퍼스 내 출현 빈도가 n번 미만인 단어는 분석에서 제외. CPU는 쿼드코어를 쓰고 100번 반복학습, 분석방법론은 Skip-Gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFhqvGR8iFOJ"
      },
      "source": [
        "# embedding_lilst3 = list(embedding_model3.wv.vocab)\r\n",
        "# do_obj3 = [list(set(dic_do).intersection(embedding_list3))]\r\n",
        "# df3 = pd.DataFrame(index = range(0, len(dic_do)), columns = ['do', 'topn1000', 'topn100_word', 'obj_words'])\r\n",
        "# df3['obj'] = dic_do"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9no7xGMi_Nn"
      },
      "source": [
        "## 1000개 단어 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUjr2QfKjCUj"
      },
      "source": [
        "# df3['topn1000'] = sim_list3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_7wozB7jHb-"
      },
      "source": [
        "## index 접근"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nffegrn1jJHY"
      },
      "source": [
        "# just_word3 = []\r\n",
        "# for i in range(0, len(df3['topn1000'])):\r\n",
        "#     if len(df3['topn1000'][i]) > 0:\r\n",
        "#         just_word3.append(list(x[0] for x  in sim_list3[i]))\r\n",
        "#     else:\r\n",
        "#         just_word3.append([])\r\n",
        "#     df3['topn1000_word'] = just_word3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ytPmACFjtUC"
      },
      "source": [
        "# df3['do_words'] = do_word3\r\n",
        "\r\n",
        "# csv 파일로 output 저장\r\n",
        "# df3.to_csv('{}'.format(idx+1), encoding = 'cp949')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}